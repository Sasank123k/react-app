package com.wellsfargo.utcap.service;
import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.node.ArrayNode;
import com.fasterxml.jackson.databind.node.ObjectNode;
import com.wellsfargo.utcap.model.*;
import com.wellsfargo.utcap.repository.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import java.util.*;

@Service
public class JsonRequirementService {
    private static final Logger LOG = LoggerFactory.getLogger(CDMPAdditionalJson.class);
    private static final String SANITIZED = "sanitized";
    private static final String INGESTION_TO = " ingestion to ";
    private static final String TABLE = " Table ";
    private static final List<Map<Object,Object>> DIMC_CHECKS_LIST = new ArrayList<>();

    @Autowired 
    public ApplicationAuthRepository applicationAuthRepository;
    @Autowired 
    public RequirementRepository requirementRepository;

    @Autowired 
    public JsonRequirementRepository jsonRequirementRepository;

    @Autowired 
    public JiraStoryIntakeRepository jiraStoryIntakeRepository;

    @Autowired 
    public SorRepository sorRepository;

    @Autowired 
    public SQLScriptRepository sqlScriptRepository;

    @Autowired 
    public ConnJsonRequirementRepository connJsonRequirementRepository;

    public JsonRequirement saveJson(String requirementId, Object newJson) {
        JsonRequirement entity = jsonRequirementRepository.findById(requirementId).orElse(new JsonRequirement(requirementId, null));
        entity.setJson(newJson);
        return jsonRequirementRepository.save(entity);
    }
    public static void populateDimcChecksList() {
        // FILE_CHECKS
        Map<Object,Object> duplicateFileLoadChecks = new HashMap<>();
        duplicateFileLoadChecks.put("dimcCheckName","duplicateFileLoadChecks");
        duplicateFileLoadChecks.put("isDimcCheckEnabled","${DUPLICATE_FILELOAD_CHECK_ENABLED}");
        duplicateFileLoadChecks.put("isFailJobOnError","${DUPLICATE_FILELOAD_CHECK_FAILURE_FLAG}");
        DIMC_CHECKS_LIST.add(duplicateFileLoadChecks);

        Map<Object,Object> dataVolumeConsistencyCheck = new HashMap<>();
        dataVolumeConsistencyCheck.put("dimcCheckName","dataVolumeConsistencyCheck");
        dataVolumeConsistencyCheck.put("isDimcCheckEnabled","${DATA_VOLUME_CONSISTENCY_CHECK_ENABLED}");
        dataVolumeConsistencyCheck.put("upperThreshold","${UPPER_THRESHOLD}");
        dataVolumeConsistencyCheck.put("lowerThreshold","${LOWER_THRESHOLD}");
        dataVolumeConsistencyCheck.put("numPastDays","${NUM_PAST_DAYS}");
        dataVolumeConsistencyCheck.put("isFailJobOnError","${DATA_VOLUME_CONSISTENCY_CHECK_FAILURE_FLAG}");
        DIMC_CHECKS_LIST.add(dataVolumeConsistencyCheck);

        Map<Object,Object> missingFileCheck = new HashMap<>();
        missingFileCheck.put("dimcCheckName","missingFileCheck");
        missingFileCheck.put("isDimcCheckEnabled","${MISSING_FILE_CHECK_ENABLED}");
        missingFileCheck.put("isFailJobOnError","${MISSING_FILE_CHECK_FAILURE_FLAG}");
        DIMC_CHECKS_LIST.add(missingFileCheck);

        Map<Object,Object> deliveryCheck = new HashMap<>();
        deliveryCheck.put("dimcCheckName","deliveryCheck");
        deliveryCheck.put("isDimcCheckEnabled","${DELIVERY_CHECK_ENABLED}");
        deliveryCheck.put("SLA","${DELIVERY_CHECK_SLA}");
        deliveryCheck.put("isFailJobOnError","${DELIVERY_CHECK_FAILURE_FLAG}");
        DIMC_CHECKS_LIST.add(deliveryCheck);

        // TABLE_CHECKS
        Map<Object,Object> missingDbObjectCheck = new HashMap<>();
        missingDbObjectCheck.put("dimcCheckName","missingDbObjectCheck");
        missingDbObjectCheck.put("isDimcCheckEnabled","${MISSING_DB_OBJECT_CHECK_ENABLED}");
        missingDbObjectCheck.put("isFailJobOnError","${MISSING_DB_OBJECT_CHECK_FAILURE_FLAG}");
        DIMC_CHECKS_LIST.add(missingDbObjectCheck);

        Map<Object,Object> emptySourceCheck = new HashMap<>();
        emptySourceCheck.put("dimcCheckName","emptySourceCheck");
        emptySourceCheck.put("isDimcCheckEnabled","${EMPTY_SOURCE_CHECK_ENABLED}");
        emptySourceCheck.put("isFailJobOnError","${EMPTY_SOURCE_CHECK_FAILURE_FLAG}");
        DIMC_CHECKS_LIST.add(emptySourceCheck);

    }

    static List<Map<Object,Object>> getChosenDimcChecksList(List<Integer> chosenIndices) {
        if (!chosenIndices.isEmpty()) {
            populateDimcChecksList();
        }
        List<Map<Object,Object>> chosenDimcChecksList = new ArrayList<>();
        for (Integer index : chosenIndices) {
            if (index >= 0 && index < DIMC_CHECKS_LIST.size()) {
                Map<Object,Object> dimcCheck = DIMC_CHECKS_LIST.get(index);
                chosen
            }
        }
        return chosenDimcChecksList;
    }


    public ConnJsonRequirement getOrCreateConnectionJsonReq(String requirementId) {
    Optional<ConnJsonRequirement> existingConnJsonRequirement =connJsonRequirementRepository.findById(requirementId);


    if (existingConnJsonRequirement.isPresent()) {
        return existingConnJsonRequirement.get();
    }
    ObjectMapper objectMapper = new ObjectMapper();
    ObjectNode rootNode      = objectMapper.createObjectNode();
    ObjectNode application   = objectMapper.createObjectNode();

    ObjectNode email         = objectMapper.createObjectNode();
    String sorName = requirementRepository.findByRequirementId(requirementId).get(0).getSorName();
    String emailBody ="<p>Hello All,</p>"+ "<p> Ingestion for " + sorName+ " with Job Name $jobName has completed.</p>"
    + "<p> SourceDate = $sourceDate , TargetDate = $targetDate </p>"+ "<p> Yarn Application ID = $yarnApplicationId</p>";

    email.put("body", emailBody);
    ObjectNode job = objectMapper.createObjectNode();
    job.set("Email", email);
    application.set("job", job);
    rootNode.set("application", application);
    Map<String, Object> json = objectMapper.convertValue(rootNode,new TypeReference<Map<String, Object>>() {});

    ConnJsonRequirement connReq = new ConnJsonRequirement(requirementId, json);
    return connJsonRequirementRepository.save(connReq);
}

    public JsonRequirement getOrCreateJsonRequirement(String requirementId) throws JsonProcessingException {
    String req = requirementId.split("-")[0];
    Optional<JsonRequirement> existingJsonRequirement = jsonRequirementRepository.findById(requirementId);

    if (existingJsonRequirement.isPresent()) {
        return existingJsonRequirement.get();
    }
    Optional<JiraStoryIntake> jiraStoryIntake = jiraStoryIntakeRepository.findById(req);
    if (jiraStoryIntake.isEmpty()) {
        return null;
    }
    JiraStoryIntake jiraStoryIntake1 = jiraStoryIntake.get();
    Sor sor = sorRepository.findBySorName(jiraStoryIntake1.getApplicationSorName()).get(0);
    if (sor == null) {
        return null;
    }
    ApplicationAuthorizer applicationAuthorizer;
    if (applicationAuthRepository.findByApplicationName(jiraStoryIntake1.getApplicationName()).isEmpty()) {
        return null;
    }
    // HARD-CODED DIMC CHECKS AS OF NOW TO BE REPLACED WITH USER INPUT
    List<Integer> chosenDimcChecks = Arrays.asList(1, 5);
    applicationAuthorizer = applicationAuthRepository.findByApplicationName(jiraStoryIntake1.getApplicationName()).get(0);
    List<SQLScript> sqlScriptList = sqlScriptRepository.findByRequirementId(jiraStoryIntake1.getJiraStoryIntakeId());
    SQLScript sqlScript = sqlScriptList.get(0);
    ObjectMapper objectMapper = new ObjectMapper();
    ObjectNode rootNode = objectMapper.createObjectNode();
    rootNode.set("application",createApplicationNode(objectMapper,jiraStoryIntake1,sor,sqlScript,applicationAuthorizer,chosenDimcChecks));
    Map<String, Object> json =objectMapper.convertValue(rootNode, new TypeReference<Map<String, Object>>() {});
    JsonRequirement jsonRequirement = new JsonRequirement(requirementId, json);
    return jsonRequirementRepository.save(jsonRequirement);

}

private static ObjectNode createApplicationNode(ObjectMapper objectMapper, JiraStoryIntake jiraStoryIntake, Sor sor, SQLScript sqlScript, ApplicationAuthorizer applicationAuthorizer, List<Integer> chosenDimChecks) throws JsonProcessingException {
    ObjectNode applicationNode = objectMapper.createObjectNode();
    applicationNode.put("isParallelProcessing", "Y");
    applicationNode.set("jobs", createJobsNode(objectMapper, jiraStoryIntake, sor, sqlScript, applicationAuthorizer, chosenDimChecks));
    return applicationNode;
}

private static ObjectNode createJobsNode(ObjectMapper objectMapper, JiraStoryIntake jiraStoryIntake, Sor sor, SQLScript sqlScript, ApplicationAuthorizer applicationAuthorizer, List<Integer> chosenDimChecks) throws JsonProcessingException {
    ObjectNode jobsNode = objectMapper.createObjectNode();
    jobsNode.set("job", createJobNode(objectMapper, jiraStoryIntake, sor, sqlScript, applicationAuthorizer, chosenDimChecks));
    return jobsNode;
}

private static ObjectNode createJobNode(ObjectMapper objectMapper, JiraStoryIntake jiraStoryIntake, Sor sor,SQLScript sqlScript, ApplicationAuthorizer applicationAuthorizer,List<Integer> chosenDimChecks) throws JsonProcessingException {
    ObjectNode jobNode = objectMapper.createObjectNode();

    if (!("gcp").equalsIgnoreCase(jiraStoryIntake.getTargetType())) {

        jobNode.put("app", jiraStoryIntake.getApplicationName());

        jobNode.put("appRemedyId", applicationAuthorizer.getAppRemedyId());
        jobNode.put("sorRemedyId", sor.getRemedyId());
        jobNode.put("queryGroup", "dim_check_" + sor.getSonName().toLowerCase(Locale.ROOT));
        jobNode.put("zone", "SANITIZED");
        jobNode.put("environment", sor.getSon().getSonEnv().toLowerCase(Locale.ROOT));
    }
    jobNode.put("jobId", jiraStoryIntake.getTableName());
    jobNode.put("jobName", sor.getSon().getName().toLowerCase(Locale.ROOT) + TABLE + jiraStoryIntake.getTableName().toLowerCase(Locale.ROOT));
    jobNode.put("jobDescription", "INGESTION_TO_" + applicationAuthorizer.getApplicationName());

    if (("gcp").equalsIgnoreCase(jiraStoryIntake.getTargetType())) {
        jobNode.put("jobDescription", "CDMP Extract for Hive table - " + jiraStoryIntake.getTableName().toLowerCase(Locale.ROOT));
    }

    jobNode.put("isJobEnabled", "Y");
    jobNode.set("Email", createEmailNode(objectMapper, jiraStoryIntake, sor));

    if (!("gcp").equalsIgnoreCase(jiraStoryIntake.getTargetType())) {
        jobNode.set("ingestions", createIngestionsNode(objectMapper, jiraStoryIntake, sor, sqlScript, chosenDimChecks));
    }

    jobNode.set("flows", createFlowsNode(objectMapper, jiraStoryIntake, sor, sqlScript, applicationAuthorizer));
    jobNode.set("datachecks", createDataChecksNode(objectMapper, jiraStoryIntake, sor, applicationAuthorizer));

    if (("gcp").equalsIgnoreCase(jiraStoryIntake.getTargetType())) {
        jobNode.set("fileExtracts", createFileExtractNode(objectMapper, jiraStoryIntake, sqlScript));
    }

    return jobNode;
}





private static ObjectNode createEmailNode(ObjectMapper objectMapper, JiraStoryIntake jiraStoryIntake, Sor sor){
    ObjectNode emailNode = objectMapper.createObjectNode();
    emailNode.put("fromAddress", "${EMAIL_TO_LIST}");
    emailNode.put("toAddress", "${EMAIL_CC_LIST}");
    emailNode.put("subject", "Data Extract from " + sor.getSourceName().toUpperCase(Locale.ROOT) + " to " + jiraStoryIntake.getApplicationName() + " " + jiraStoryIntake.getTableName().toLowerCase(Locale.ROOT));

    if(("gcp").equalsIgnoreCase(jiraStoryIntake.getTargetType())){
        emailNode.put("fromAddress", "${FROM_EMAIL}");
        emailNode.put("toAddress", "${TO_EMAIL}");
        emailNode.put("subject", "CDMP Extraction - " + jiraStoryIntake.getTableName().toLowerCase(Locale.ROOT));
    }
    emailNode.put("isPriorityAlert", "Y");
    return emailNode;
}
