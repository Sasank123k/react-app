Here are the updated backend files with the requested mapping change (using `INTEGER` instead of `INT64`), the new column‑vs‑types parsing logic, and Sonar issues addressed (magic numbers, generic exceptions, mutable map exposure, logging, etc.).

---

## 1. `ResourceNotFoundException.java`

A dedicated exception class for missing records (replaces all those generic `RuntimeException`s).

```java
package com.wellsfargo.utcap.exception;

public class ResourceNotFoundException extends RuntimeException {
    public ResourceNotFoundException(String message) {
        super(message);
    }
}
```

---

## 2. `SqlDatatype.java`  
Defensive copying and unmodifiable getters to avoid exposing internal state.

```java
package com.wellsfargo.utcap.model;

import org.springframework.data.annotation.Id;
import org.springframework.data.mongodb.core.mapping.Document;

import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import java.util.Objects;

@Document(collection = "sqlDatatype")
public class SqlDatatype {

    @Id
    private String id;
    private Map<String, String> mappings = new HashMap<>();

    public SqlDatatype() { }

    public SqlDatatype(String id, Map<String, String> mappings) {
        this.id = id;
        setMappings(mappings);
    }

    public String getId() {
        return id;
    }

    public void setId(String id) {
        this.id = id;
    }

    /**
     * Returns an unmodifiable view to prevent external mutation.
     */
    public Map<String, String> getMappings() {
        return Collections.unmodifiableMap(mappings);
    }

    /**
     * Defensive copy to avoid storing an external map reference.
     */
    public void setMappings(Map<String, String> mappings) {
        this.mappings = mappings == null
            ? new HashMap<>()
            : new HashMap<>(mappings);
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (!(o instanceof SqlDatatype)) return false;
        SqlDatatype that = (SqlDatatype) o;
        return Objects.equals(id, that.id) &&
               Objects.equals(mappings, that.mappings);
    }

    @Override
    public int hashCode() {
        return Objects.hash(id, mappings);
    }
}
```

---

## 3. `DagSqlService.java`  
- Extracts column names from `HiveTable.getColumnName()` (CSV)  
- Extracts types from `HiveTable.getFileSetAttr()` (pipe‑delimited pairs)  
- Uses named constants instead of magic numbers/strings  
- Throws `ResourceNotFoundException` for missing records  

```java
package com.wellsfargo.utcap.service;

import com.wellsfargo.utcap.exception.ResourceNotFoundException;
import com.wellsfargo.utcap.model.DagSql;
import com.wellsfargo.utcap.model.HiveTable;
import com.wellsfargo.utcap.model.JiraStoryIntake;
import com.wellsfargo.utcap.model.SqlDatatype;
import com.wellsfargo.utcap.repository.DagSqlRepository;
import com.wellsfargo.utcap.repository.HiveTableRepository;
import com.wellsfargo.utcap.repository.JiraStoryIntakeRepository;
import com.wellsfargo.utcap.repository.SqlDatatypeRepository;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.time.LocalDateTime;
import java.util.*;

@Service
public class DagSqlService {

    private static final int    TOKEN_STEP         = 2;
    private static final String DEFAULT_MAPPING_ID = "defaultMapping";
    private static final String CREATE_TEMPLATE    = "CREATE TABLE %s(\n%s\n);";
    private static final String DROP_TEMPLATE      = "DROP TABLE %s";

    @Autowired
    private DagSqlRepository dagSqlRepository;

    @Autowired
    private JiraStoryIntakeRepository jiraStoryIntakeRepository;

    @Autowired
    private HiveTableRepository hiveTableRepository;

    @Autowired
    private SqlDatatypeRepository sqlDatatypeRepository;

    public DagSql getDagSql(String requirementId) {
        return dagSqlRepository
            .findByRequirementId(requirementId)
            .orElseGet(() -> generateAndSaveDagSql(requirementId));
    }

    public DagSql generateAndSaveDagSql(String requirementId) {
        JiraStoryIntake jiraStory = jiraStoryIntakeRepository
            .findById(requirementId)
            .orElseThrow(() -> new ResourceNotFoundException(
                "JiraStoryIntake not found for requirementId: " + requirementId));

        String schema = jiraStory.getTargetSchema();
        String table  = jiraStory.getTargetTableName();
        String identifier = schema + "." + table;

        List<HiveTable> hiveTables = hiveTableRepository.findByTableName(identifier);
        HiveTable hiveTable = Optional.ofNullable(hiveTables)
            .filter(list -> !list.isEmpty())
            .map(list -> list.get(0))
            .orElseThrow(() -> new ResourceNotFoundException(
                "HiveTable not found for: " + identifier));

        SqlDatatype sqlDatatype = sqlDatatypeRepository
            .findById(DEFAULT_MAPPING_ID)
            .orElseGet(this::getDefaultSqlDatatype);
        Map<String, String> mapping = sqlDatatype.getMappings();

        String columns = generateColumnDefinitions(
            hiveTable.getColumnName(),
            hiveTable.getFileSetAttr(),
            mapping);

        String createSql = String.format(CREATE_TEMPLATE, identifier, columns);
        String deleteSql = String.format(DROP_TEMPLATE, identifier);

        DagSql record = new DagSql();
        record.setRequirementId(requirementId);
        record.setCreateSqlContent(createSql);
        record.setDeleteSqlContent(deleteSql);
        record.setCreatedAt(LocalDateTime.now());
        record.setUpdatedAt(LocalDateTime.now());

        return dagSqlRepository.save(record);
    }

    private String generateColumnDefinitions(
        String columnCsv,
        String fileSetAttr,
        Map<String, String> mapping
    ) {
        String[] columns = columnCsv.split(",");
        String[] tokens  = fileSetAttr.split("\\|");

        List<String> cleaned = new ArrayList<>();
        for (String token : tokens) {
            if (token != null && !token.trim().isEmpty()) {
                cleaned.add(token.trim());
            }
        }

        if (cleaned.size() % TOKEN_STEP != 0) {
            throw new IllegalArgumentException(
                "Invalid fileSetAttr format; even number of tokens expected");
        }

        // extract every second token as the Hive type
        List<String> types = new ArrayList<>();
        for (int i = 1; i < cleaned.size(); i += TOKEN_STEP) {
            types.add(cleaned.get(i).toUpperCase(Locale.ROOT));
        }

        StringBuilder builder = new StringBuilder();
        for (int i = 0; i < columns.length; i++) {
            String colName = columns[i].trim();
            String hiveType = i < types.size() ? types.get(i) : "";
            String baseType = hiveType.contains("(")
                ? hiveType.substring(0, hiveType.indexOf('('))
                : hiveType;
            String bqType = mapping.getOrDefault(baseType, "STRING");

            builder
                .append("  ")
                .append(colName)
                .append(" ")
                .append(bqType);

            if (i < columns.length - 1) {
                builder.append(',').append('\n');
            }
        }
        return builder.toString();
    }

    public DagSql updateDagSql(
        String requirementId,
        String createSql,
        String deleteSql
    ) {
        DagSql existing = dagSqlRepository
            .findByRequirementId(requirementId)
            .orElseThrow(() -> new ResourceNotFoundException(
                "DagSql record not found for requirementId: " + requirementId));

        existing.setCreateSqlContent(createSql);
        existing.setDeleteSqlContent(deleteSql);
        existing.setUpdatedAt(LocalDateTime.now());

        return dagSqlRepository.save(existing);
    }

    private SqlDatatype getDefaultSqlDatatype() {
        Map<String, String> def = new HashMap<>();
        def.put("STRING",  "STRING");
        def.put("CHAR",    "STRING");
        def.put("VARCHAR", "STRING");
        def.put("INT",     "INTEGER");
        def.put("INTEGER", "INTEGER");
        def.put("BIGINT",  "INTEGER");
        def.put("SMALLINT","INTEGER");
        def.put("TINYINT", "INTEGER");
        def.put("BOOLEAN", "BOOLEAN");
        def.put("FLOAT",   "FLOAT");
        def.put("DOUBLE",  "FLOAT");
        def.put("DECIMAL", "NUMERIC");
        def.put("DATE",    "DATE");
        def.put("TIMESTAMP","TIMESTAMP");
        def.put("BINARY",  "BYTES");

        return new SqlDatatype(DEFAULT_MAPPING_ID, def);
    }
}
```

---

## 4. `DagSqlController.java`  
Logs all errors, distinguishes **404** vs **500**, and removes unused imports/inline comments.

```java
package com.wellsfargo.utcap.controller;

import com.wellsfargo.utcap.exception.ResourceNotFoundException;
import com.wellsfargo.utcap.model.DagSql;
import com.wellsfargo.utcap.service.DagSqlService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping("/api/sql")
public class DagSqlController {

    private static final Logger LOGGER = LoggerFactory.getLogger(DagSqlController.class);

    @Autowired
    private DagSqlService dagSqlService;

    @GetMapping("/{requirementId}")
    public ResponseEntity<DagSql> getDagSql(@PathVariable String requirementId) {
        try {
            DagSql sql = dagSqlService.getDagSql(requirementId);
            return ResponseEntity.ok(sql);
        } catch (ResourceNotFoundException e) {
            LOGGER.error("Not found: {}", requirementId, e);
            return ResponseEntity.status(HttpStatus.NOT_FOUND).build();
        } catch (Exception e) {
            LOGGER.error("Error fetching DagSql for {}", requirementId, e);
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build();
        }
    }

    @PostMapping("/{requirementId}")
    public ResponseEntity<DagSql> updateDagSql(
        @PathVariable String requirementId,
        @RequestBody DagSql updatedSql
    ) {
        try {
            DagSql saved = dagSqlService.updateDagSql(
                requirementId,
                updatedSql.getCreateSqlContent(),
                updatedSql.getDeleteSqlContent()
            );
            return ResponseEntity.ok(saved);
        } catch (ResourceNotFoundException e) {
            LOGGER.error("Not found on update: {}", requirementId, e);
            return ResponseEntity.status(HttpStatus.NOT_FOUND).build();
        } catch (Exception e) {
            LOGGER.error("Error updating DagSql for {}", requirementId, e);
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build();
        }
    }
}
```

---

With these changes you now have:

- **Dedicated exception** for 404 scenarios.  
- **Defensive collections** in `SqlDatatype`.  
- **No magic numbers/strings** littered in code (all pulled into constants).  
- **Proper logging** in the controller catches.  
- **Accurate column‑vs‑type pairing** (using both `columnName` and `fileSetAttr`).  
- **INTEGER** used throughout instead of `INT64`.  

That should clear the Sonar flags and align the code with your updated parsing and mapping requirements. Let me know if any further tweaks are needed!
